---
layout: post
title: 如何设计VUI?

---
习惯了图形界面思维的交互设计师，刚开始接触VUI的时候想必也和我在2015年的时候一样，不知道如何下手。
语音技术经历了这几年的发展已经在不同的产品上随处可见了，比如智能音箱、chatbot、陪伴机器人、聊天应用、社交应用…并且巨头也构建了各自的语音开放平台，语音技术的应用已经没有我当年那么困难了。
但如何设计语音交互界面甚至说多模态交互界面对没有涉及到这个领域的设计师来说还是有一定的门槛和学习成本的。
这篇文章主要和大家分享一下我在设计VUI甚至是多模态交互的心得与经验。

对于交互设计师来说，要掌握语音类产品的交互设计，需要：
- 了解语音相关技术
- 将交互与语音技术相结合
- 输出多模态交互设计文档

### 语音相关技术
- ASR
Automatic Speech Recognition，语音识别，即将声音转化为文字的步骤，包括在线语音识别、离线语音识别两种方式。
当使用在线方式识别语音时，首先在设备端“录制音频”，然后将“音频上传”至云端，完成“语音转文字”。
使用离线的方式时，语音转文字的步骤在本地进行不需要上传至云端，效率会比在线语音识别更快，但能够识别的语音是有限的。

- NLU
Natural Language Understanding，自然语言理解，即将文字转化为结构化的数据。


### 语音交互流程
在用户与语音助手交互时，语音助手一般需要经过“唤醒”“识别”“思考”“响应”“结束”五个主要过程。在各个主流程的子流程中，语音助手处于的一系列状态。如下图：
![在线语音交互流程](/assets/VUI/online_vui_process.png)
1. 唤醒：用户使用唤醒词唤醒语音助手的过程（通过唤醒次开启麦克风并录音）。
2. 响应唤醒：当设备识别到唤醒词并做出响应的状态。
3. 识别：语音助手识别用户语音输入的过程（开始对用户的语音输入进行录音）。
4. 等待识别：在设备唤醒状态时，检测语音输入的状态。即ASR等待采集音频流的过程。
5. 主动语音提示：当设备超过5秒没有识别到语音时，语音助手给出语音输入提醒的状态。
6. 语音识别：当设备检测到语音输入的状态。即ASR采集音频流的过程。
7. 理解/思考：语音助手通过在线语音平台/离线语音引擎以及AIoT等平台处理用户语音输入的过程。
8. 等待响应：设备等待在线语音平台返回结果时的状态，由以下过程组成；
    （1）将采集到的音频流传到在线语音识别引擎，并由在线语音识别引擎并转化为文字（语音转文字）；
    （2）在线语音平台对步骤（1）的文字进行理解（语音理解，即NLU)
    （3）等待接收在线语音平台对步骤（2）的回复(回复生成，即DLG)
9. 响应：语音助手根据在线语音平台/离线语音引擎以及AIoT等平台的结果处理用户输入并产生的界面和语音反馈的过程()。
10. 识别失败响应：当在线语音平台没有成功完成“等待响应的步骤（1）”并返回的结果时，语音助手的响应状态。
11. 识别成功相应：当在线语音平台成功识别到
    结束：语音助手完成用户语音输入响应的过程。
    会话结束：语音助手完成一个语音交互流程的状态。
    退出唤醒：语音助手返回需要唤醒的状态。

### 语音交互详情
用户与语音助手进行多模态交互的流程，即语音助手在不同状态下“屏幕”显示以及“语音”播报的整体效果，以及不同状态的进入以及退出条件。
 
![vui交互表格](/assets/VUI/VUI交互表格.jpg)
1. 响应唤醒 
- 进入条件：识别到唤醒词
- 屏幕：语音助手执行“唤醒”动效知直到语音播报结束
- 语音：播放“唤醒”语料
- 退出：进入“等待识别”状态

2. 等待识别 
- 进入条件：
    1. “响应唤醒”状态结束后 
    2. “主动语音提醒”状态结束后
- 屏幕：语音助手循环执行“等待”动效
- 语音：无
- 退出：
    1. 当识别到语音输入时，进入“语音识别”状态
    2. 当超过5秒没有识别到语音时，进入“主动语音提醒”状态
    3. 从“主动语音提醒”状态返回“等待识别”状态时超过10秒没有识别到语音，进入“退出唤醒”状态。
3. 主动语音提醒
- 进入条件：当超过5秒没有识别到语音
- 屏幕：语音助手循环执行“说话”动效直到语音播报结束
- 语音：播报“主动提醒”语料
- 退出：返回“等待识别”状态
4. 语音识别 
- 进入条件：在“等待识别”状态时，识别到语音输入
- 屏幕：语音助手循环执行“倾听”动效直到语音识别结束
- 语音：无
- 退出：当语音识别结束之后进入“等待响应”状态
5. 等待响应 
- 进入条件：“语音识别”结束后
- 屏幕：语音助手循环执行“思考”动效
- 语音：无
- 退出：
    1. 语音识别不成功后返回“识别错误”状态
    2. 语音识别成功后但没有成功匹配进入“异常类响应”状态
    3. 语音识别成功后场景匹配成功，进入“场景类响应”状态
    4. 语音识别成功后意图匹配成功，进入“意图类响应”状态。
    5. 语音识别成功但在15秒内没有匹配，进入“超时类响应”。
6. 识别失败 
- 进入条件：语音识别不成功
- 屏幕：语音助手循环执行“说话”动效直到语音播报结束
- 语音：播报“识别失败”语料
- 退出：进入“等待识别”状态
7. 场景类响应 
- 进入条件：语音识别成功后场景匹配成功时
- 屏幕：语音助手显示“场景响应”动画，具体动画描述TBD。
- 语音：语音播报“场景匹配类”回复
- 退出：响应结束后进入“会话结束”状态
8. 意图类响应 
- 进入条件：语音识别成功后意图匹配成功时
- 屏幕：语音助手显示“意图响应”动画。
- 语音：语音播报场景“意图匹配类回复”
- 退出：响应结束后进入“会话结束”状态
9. 异常响应 
- 进入条件：语音识别成功后但没有成功匹配
- 屏幕：语音助手循环执行“说话”动效直到语音播报结束
- 语音：语音播报“异常回复”
- 退出：响应结束后进入“会话结束”状态
10. 超时响应 
- 进入条件：语音识别成功但在15秒内没有匹配
- 屏幕：语音助手淡出，返回唤醒前页面
- 语音：语音播报“超时响应”
- 退出：响应结束后进入“会话结束”状态
11. 会话结束
- 进入条件：
    1. 从“主动语音提醒”状态返回“等待识别”状态时超过10秒没有识别到语音
    2. “识别错误”后
    3. “响应”后
- 屏幕：语音助手淡出，返回唤醒前页面
- 语音：无
- 退出：返回会话前页面
12. 退出唤醒
- 进入条件：“会话结束”后15秒没有再识别到语音
- 屏幕：无
- 语音：无
- 退出：语音助手进入需要唤醒的状态

### 多模态交互
多模态即在某一个交互节点时交互对象的多种输出形式。
对于机器人来说，多模态就是当机器人接收到用户输入后所输出的“动作”、“声音”、“语音”、“表情”等一系列反馈。
对于语音助手来说，多模态就是当语音助手接收到用户输入后语音助手所呈现的“界面”、“文本”、“语音”等一系列输出。
在“语音交互详情”中，每一个交互步骤除了进入条件和退出条件外，还包括了屏幕显示和语音播报。
这跟Choregraphe中的Flow diagram box非常相似。